{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Predicting Movie Ratings using Collaborative Filtering**\n",
    "#### According to Wikipedia, collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a person chosen randomly. We will use a subset dataset of 500,000 ratings from the [movielens 10M stable benchmark rating dataset](http://grouplens.org/datasets/movielens/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from test_helper import Test\n",
    "\n",
    "baseDir = os.path.join('data')\n",
    "inputPath = os.path.join('cs100', 'lab4', 'small')\n",
    "\n",
    "ratingsFilename = os.path.join(baseDir, inputPath, 'ratings.dat.gz')\n",
    "moviesFilename = os.path.join(baseDir, inputPath, 'movies.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 0: Parsing the data**\n",
    "#### We read in each of the files and create an RDD consisting of parsed lines.\n",
    "#### Each line in the ratings dataset (`ratings.dat.gz`) is formatted as:\n",
    "####   `UserID::MovieID::Rating::Timestamp`\n",
    "#### Each line in the movies (`movies.dat`) dataset is formatted as:\n",
    "####   `MovieID::Title::Genres`\n",
    "#### The `Genres` field has the format\n",
    "####   `Genres1|Genres2|Genres3|...`\n",
    "\n",
    "#### Parsing the two files yields two RDDS\n",
    "* #### For each line in the ratings dataset, we create a tuple of (UserID, MovieID, Rating).  \n",
    "* #### For each line in the movies dataset, we create a tuple of (MovieID, Title).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 487650 ratings and 3883 movies in the datasets\n",
      "Ratings: [(1, 1193, 5.0), (1, 914, 3.0), (1, 2355, 5.0)]\n",
      "Movies: [(1, u'Toy Story (1995)'), (2, u'Jumanji (1995)'), (3, u'Grumpier Old Men (1995)')]\n"
     ]
    }
   ],
   "source": [
    "numPartitions = 2\n",
    "rawRatings = sc.textFile(ratingsFilename).repartition(numPartitions)\n",
    "rawMovies = sc.textFile(moviesFilename)\n",
    "\n",
    "def get_ratings_tuple(entry):\n",
    "    \"\"\" Parse a line in the ratings dataset\n",
    "    Args:\n",
    "        entry (str): a line in the ratings dataset in the form of UserID::MovieID::Rating::Timestamp\n",
    "    Returns:\n",
    "        tuple: (UserID, MovieID, Rating)\n",
    "    \"\"\"\n",
    "    items = entry.split('::')\n",
    "    return int(items[0]), int(items[1]), float(items[2])\n",
    "\n",
    "\n",
    "def get_movie_tuple(entry):\n",
    "    \"\"\" Parse a line in the movies dataset\n",
    "    Args:\n",
    "        entry (str): a line in the movies dataset in the form of MovieID::Title::Genres\n",
    "    Returns:\n",
    "        tuple: (MovieID, Title)\n",
    "    \"\"\"\n",
    "    items = entry.split('::')\n",
    "    return int(items[0]), items[1]\n",
    "\n",
    "\n",
    "ratingsRDD = rawRatings.map(get_ratings_tuple).cache()\n",
    "moviesRDD = rawMovies.map(get_movie_tuple).cache()\n",
    "\n",
    "ratingsCount = ratingsRDD.count()\n",
    "moviesCount = moviesRDD.count()\n",
    "\n",
    "print 'There are %s ratings and %s movies in the datasets' % (ratingsCount, moviesCount)\n",
    "print 'Ratings: %s' % ratingsRDD.take(3)\n",
    "print 'Movies: %s' % moviesRDD.take(3)\n",
    "\n",
    "assert ratingsCount == 487650\n",
    "assert moviesCount == 3883\n",
    "assert moviesRDD.filter(lambda (id, title): title == 'Toy Story (1995)').count() == 1\n",
    "assert (ratingsRDD.takeOrdered(1, key=lambda (user, movie, rating): movie)\n",
    "        == [(1, 1, 5.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We sort the RDD by *both the key and value*, which we can do by combining the key and value into a single string and then sorting on that string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sortFunction(tuple):\n",
    "    \"\"\" Construct the sort string (does not perform actual sorting)\n",
    "    Args:\n",
    "        tuple: (rating, MovieName)\n",
    "    Returns:\n",
    "        sortString: the value to sort with, 'rating MovieName'\n",
    "    \"\"\"\n",
    "    key = unicode('%.3f' % tuple[0])\n",
    "    value = tuple[1]\n",
    "    return (key + ' ' + value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1: Basic Recommendations**\n",
    "#### One way to recommend movies is to always recommend the movies with the highest average rating. In this part, we will find the name, number of ratings, and the average rating of the 20 movies with the highest average rating and more than 500 reviews. We want to filter our movies with high ratings but fewer than or equal to 500 reviews because movies with few reviews may not have broad appeal to everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1a) Number of Ratings and Average Ratings for a Movie**\n",
    "#### The following function `getCountsAndAverages()` takes a single tuple of (MovieID, (Rating1, Rating2, Rating3, ...)) and returns a tuple of (MovieID, (number of ratings, averageRating)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, (4, 2.5))\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import math\n",
    "# First, implement a helper function `getCountsAndAverages` using only Python\n",
    "def getCountsAndAverages(IDandRatingsTuple):\n",
    "    \"\"\" Calculate average rating\n",
    "    Args:\n",
    "        IDandRatingsTuple: a single tuple of (MovieID, (Rating1, Rating2, Rating3, ...))\n",
    "    Returns:\n",
    "        tuple: a tuple of (MovieID, (number of ratings, averageRating))\n",
    "    \"\"\"\n",
    "    nr= len(IDandRatingsTuple[1])\n",
    "    av= float(sum(IDandRatingsTuple[1]))/nr\n",
    "    id = IDandRatingsTuple[0]\n",
    "    return (id, (nr,av))\n",
    "print getCountsAndAverages((1, (1, 2, 3, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1b) Movies with Highest Average Ratings**\n",
    "#### We will use the `getCountsAndAverages()` helper function with Spark to determine movies with highest average ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieIDsWithRatingsRDD: [(2, <pyspark.resultiterable.ResultIterable object at 0xb1f9776c>), (4, <pyspark.resultiterable.ResultIterable object at 0xb1f97c2c>), (6, <pyspark.resultiterable.ResultIterable object at 0xb1f97c4c>)]\n",
      "\n",
      "movieIDsWithAvgRatingsRDD: [(2, (332, 3.174698795180723)), (4, (71, 2.676056338028169)), (6, (442, 3.7918552036199094))]\n",
      "\n",
      "movieNameWithAvgRatingsRDD: [(3.6818181818181817, u'Happiest Millionaire, The (1967)', 22), (3.0468227424749164, u'Grumpier Old Men (1995)', 299), (2.882978723404255, u'Hocus Pocus (1993)', 94)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# From ratingsRDD with tuples of (UserID, MovieID, Rating) create an RDD with tuples of\n",
    "# the (MovieID, iterable of Ratings for that MovieID)\n",
    "movieIDsWithRatingsRDD = (ratingsRDD\n",
    "                          .map(lambda x: (x[1],x[2]))\n",
    "                          .groupByKey())\n",
    "print 'movieIDsWithRatingsRDD: %s\\n' % movieIDsWithRatingsRDD.take(3)\n",
    "\n",
    "# Using `movieIDsWithRatingsRDD`, compute the number of ratings and average rating for each movie to\n",
    "# yield tuples of the form (MovieID, (number of ratings, average rating))\n",
    "movieIDsWithAvgRatingsRDD = movieIDsWithRatingsRDD.map(lambda x: getCountsAndAverages(x))\n",
    "print 'movieIDsWithAvgRatingsRDD: %s\\n' % movieIDsWithAvgRatingsRDD.take(3)\n",
    "\n",
    "# To `movieIDsWithAvgRatingsRDD`, apply RDD transformations that use `moviesRDD` to get the movie\n",
    "# names for `movieIDsWithAvgRatingsRDD`, yielding tuples of the form\n",
    "# (average rating, movie name, number of ratings)\n",
    "movieNameWithAvgRatingsRDD = (moviesRDD\n",
    "                              .join(movieIDsWithAvgRatingsRDD)\n",
    "                              .map(lambda x: (x[1]))\n",
    "                              .map(lambda x: (x[1][1],x[0],x[1][0]))\n",
    "                              )\n",
    "print 'movieNameWithAvgRatingsRDD: %s\\n' % movieNameWithAvgRatingsRDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1c) Movies with Highest Average Ratings and more than 500 reviews**\n",
    "#### The 20 movies with highest average ratings and more than 500 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with highest ratings: [(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088), (4.515798462852263, u\"Schindler's List (1993)\", 1171), (4.512893982808023, u'Godfather, The (1972)', 1047), (4.510460251046025, u'Raiders of the Lost Ark (1981)', 1195), (4.505415162454874, u'Usual Suspects, The (1995)', 831), (4.457256461232604, u'Rear Window (1954)', 503), (4.45468509984639, u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 651), (4.43953006219765, u'Star Wars: Episode IV - A New Hope (1977)', 1447), (4.4, u'Sixth Sense, The (1999)', 1110), (4.394285714285714, u'North by Northwest (1959)', 700), (4.379506641366224, u'Citizen Kane (1941)', 527), (4.375, u'Casablanca (1942)', 776), (4.363975155279503, u'Godfather: Part II, The (1974)', 805), (4.358816276202219, u\"One Flew Over the Cuckoo's Nest (1975)\", 811), (4.358173076923077, u'Silence of the Lambs, The (1991)', 1248), (4.335826477187734, u'Saving Private Ryan (1998)', 1337), (4.326241134751773, u'Chinatown (1974)', 564), (4.325383304940375, u'Life Is Beautiful (La Vita \\ufffd bella) (1997)', 587), (4.324110671936759, u'Monty Python and the Holy Grail (1974)', 759), (4.3096, u'Matrix, The (1999)', 1250)]\n"
     ]
    }
   ],
   "source": [
    "# Apply an RDD transformation to `movieNameWithAvgRatingsRDD` to limit the results to movies with\n",
    "# ratings from more than 500 people. We then use the `sortFunction()` helper function to sort by the\n",
    "# average rating to get the movies in order of their rating (highest rating first)\n",
    "movieLimitedAndSortedByRatingRDD = (movieNameWithAvgRatingsRDD\n",
    "                                    .filter(lambda x: x[2]>500)\n",
    "                                    .sortBy(sortFunction, False))\n",
    "print 'Movies with highest ratings: %s' % movieLimitedAndSortedByRatingRDD.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2: Collaborative Filtering**\n",
    "#### Collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a person chosen randomly.  \n",
    "#### The image below (from [Wikipedia][collab]) shows an example of predicting of the user's rating using collaborative filtering. At first, people rate different items (like videos, images, games). After that, the system is making predictions about a user's rating for an item, which the user has not rated yet. These predictions are built upon the existing ratings of other users, who have similar ratings with the active user. For instance, in the image below the system has made a prediction, that the active user will not like the video.\n",
    "![collaborative filtering](https://courses.edx.org/c4x/BerkeleyX/CS100.1x/asset/Collaborative_filtering.gif)\n",
    "[mllib]: https://spark.apache.org/mllib/\n",
    "[collab]: https://en.wikipedia.org/?title=Collaborative_filtering\n",
    "[collab2]: http://recommender-systems.org/collaborative-filtering/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For movie recommendations, we start with a matrix whose entries are movie ratings by users (shown in red in the diagram below).  Each column represents a user (shown in green) and each row represents a particular movie (shown in blue).\n",
    "#### Since not all users have rated all movies, we do not know all of the entries in this matrix, which is precisely why we need collaborative filtering.  For each user, we have ratings for only a subset of the movies.  With collaborative filtering, the idea is to approximate the ratings matrix by factorizing it as the product of two matrices: one that describes properties of each user (shown in green), and one that describes properties of each movie (shown in blue).\n",
    "![factorization](http://spark-mooc.github.io/web-assets/images/matrix_factorization.png)\n",
    "#### We want to select these two matrices such that the error for the users/movie pairs where we know the correct ratings is minimized.  The [Alternating Least Squares][als] algorithm does this by first randomly filling the users matrix with values and then optimizing the value of the movies such that the error is minimized.  Then, it holds the movies matrix constrant and optimizes the value of the user's matrix.  This alternation between which matrix to optimize is the reason for the \"alternating\" in the name.\n",
    "#### This optimization is what's being shown on the right in the image above.  Given a fixed set of user factors (i.e., values in the users matrix), we use the known ratings to find the best values for the movie factors using the optimization written at the bottom of the figure.  Then we \"alternate\" and pick the best user factors given fixed movie factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2a) Creating a Training Set**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 292716, validation: 96902, test: 98032\n",
      "\n",
      "[(1, 914, 3.0), (1, 2355, 5.0), (1, 595, 5.0)]\n",
      "[(1, 1287, 5.0), (1, 594, 4.0), (1, 1270, 5.0)]\n",
      "[(1, 1193, 5.0), (1, 2398, 4.0), (1, 1035, 5.0)]\n"
     ]
    }
   ],
   "source": [
    "trainingRDD, validationRDD, testRDD = ratingsRDD.randomSplit([6, 2, 2], seed=0L)\n",
    "\n",
    "print 'Training: %s, validation: %s, test: %s\\n' % (trainingRDD.count(),\n",
    "                                                    validationRDD.count(),\n",
    "                                                    testRDD.count())\n",
    "print trainingRDD.take(3)\n",
    "print validationRDD.take(3)\n",
    "print testRDD.take(3)\n",
    "\n",
    "assert trainingRDD.count() == 292716\n",
    "assert validationRDD.count() == 96902\n",
    "assert testRDD.count() == 98032\n",
    "\n",
    "assert trainingRDD.filter(lambda t: t == (1, 914, 3.0)).count() == 1\n",
    "assert trainingRDD.filter(lambda t: t == (1, 2355, 5.0)).count() == 1\n",
    "assert trainingRDD.filter(lambda t: t == (1, 595, 5.0)).count() == 1\n",
    "\n",
    "assert validationRDD.filter(lambda t: t == (1, 1287, 5.0)).count() == 1\n",
    "assert validationRDD.filter(lambda t: t == (1, 594, 4.0)).count() == 1\n",
    "assert validationRDD.filter(lambda t: t == (1, 1270, 5.0)).count() == 1\n",
    "\n",
    "assert testRDD.filter(lambda t: t == (1, 1193, 5.0)).count() == 1\n",
    "assert testRDD.filter(lambda t: t == (1, 2398, 4.0)).count() == 1\n",
    "assert testRDD.filter(lambda t: t == (1, 1035, 5.0)).count() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After splitting the dataset, your training set has about 293,000 entries and the validation and test sets each have about 97,000 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2b) Root Mean Square Error (RMSE)**\n",
    "\n",
    "\n",
    "#### Given two ratings RDDs, *x* and *y* of size *n*, we define RSME as follows: $ RMSE = \\sqrt{\\frac{\\sum_{i = 1}^{n} (x_i - y_i)^2}{n}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " \n",
    "import math\n",
    "\n",
    "def computeError(predictedRDD, actualRDD):\n",
    "    \"\"\" Compute the root mean squared error between predicted and actual\n",
    "    Args:\n",
    "        predictedRDD: predicted ratings for each movie and each user where each entry is in the form\n",
    "                      (UserID, MovieID, Rating)\n",
    "        actualRDD: actual ratings where each entry is in the form (UserID, MovieID, Rating)\n",
    "    Returns:\n",
    "        RSME (float): computed RSME value\n",
    "    \"\"\"\n",
    "    # Transform predictedRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    predictedReformattedRDD = predictedRDD.map(lambda x: ((x[0],x[1]),x[2]))\n",
    "    print predictedReformattedRDD.top(3)\n",
    "    # Transform actualRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    actualReformattedRDD = actualRDD.map(lambda x: ((x[0],x[1]),x[2]))\n",
    "    print actualReformattedRDD.top(3)\n",
    "    # Compute the squared error for each matching entry (i.e., the same (User ID, Movie ID) in each\n",
    "    # RDD) in the reformatted RDDs using RDD transformtions - do not use collect()\n",
    "    squaredErrorsRDD = (predictedReformattedRDD\n",
    "                        .join(actualReformattedRDD)\n",
    "                        .map(lambda x: x[1])\n",
    "                        .map(lambda x: (x[1]-x[0])**2))\n",
    "    print squaredErrorsRDD.top(3)\n",
    "    # Compute the total squared error - do not use collect()\n",
    "    totalError = squaredErrorsRDD.reduce(lambda x,y: x+y)\n",
    "    print totalError\n",
    "    # Count the number of entries for which you computed the total squared error\n",
    "    numRatings = squaredErrorsRDD.count()\n",
    "    print numRatings\n",
    "    # Using the total squared error and the number of entries, compute the RSME\n",
    "    return  math.sqrt(totalError/float(numRatings))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2c) Using ALS.train()**\n",
    "#### In this part, we will use the MLlib implementation of Alternating Least Squares, [ALS.train()](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.ALS). ALS takes a training dataset (RDD) and several parameters that control the model creation process. To determine the best values for the parameters, we will use ALS to train several models, and then we will select the best model and use the parameters from that model in the rest of this lab exercise.\n",
    "#### The process we will use for determining the best model is as follows:\n",
    "* #### Pick a set of model parameters. The most important parameter to `ALS.train()` is the *rank*, which is the number of rows in the Users matrix (green in the diagram above) or the number of columns in the Movies matrix (blue in the diagram above). (In general, a lower rank will mean higher error on the training dataset, but a high rank may lead to [overfitting](https://en.wikipedia.org/wiki/Overfitting).)  We will train models with ranks of 4, 8, and 12 using the `trainingRDD` dataset.\n",
    "* #### Create a model using `ALS.train(trainingRDD, rank, seed=seed, iterations=iterations, lambda_=regularizationParameter)` with three parameters: an RDD consisting of tuples of the form (UserID, MovieID, rating) used to train the model, an integer rank (4, 8, or 12), a number of iterations to execute (we will use 5 for the `iterations` parameter), and a regularization coefficient (we will use 0.1 for the `regularizationParameter`).\n",
    "* #### For the prediction step, create an input RDD, `validationForPredictRDD`, consisting of (UserID, MovieID) pairs that you extract from `validationRDD`. You will end up with an RDD of the form: `[(1, 1287), (1, 594), (1, 1270)]`\n",
    "* #### Using the model and `validationForPredictRDD`, we can predict rating values by calling [model.predictAll()](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.MatrixFactorizationModel.predictAll) with the `validationForPredictRDD` dataset, where `model` is the model we generated with ALS.train().  `predictAll` accepts an RDD with each entry in the format (userID, movieID) and outputs an RDD with each entry in the format (userID, movieID, rating).\n",
    "* #### Evaluate the quality of the model by using the `computeError()` function in part (2b) to compute the error between the predicted ratings and the actual ratings in `validationRDD`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((2999, 3799), 1.1362232320180086), ((2999, 3397), 3.30229790721614), ((2999, 3396), 3.544613411484317)]\n",
      "[((2999, 3799), 1.0), ((2999, 3397), 4.0), ((2999, 3396), 4.0)]\n",
      "[26.597665192219818, 22.457186439678672, 18.24543666717033]\n",
      "77180.6903794\n",
      "96842\n",
      "For rank 4 the RMSE is 0.892734779484\n",
      "[((2999, 3799), 1.0684802630578876), ((2999, 3397), 3.2465350442298857), ((2999, 3396), 3.4882563067864822)]\n",
      "[((2999, 3799), 1.0), ((2999, 3397), 4.0), ((2999, 3396), 4.0)]\n",
      "[16.733415005766243, 15.681245112060461, 15.124201521856964]\n",
      "76729.4578332\n",
      "96842\n",
      "For rank 8 the RMSE is 0.890121292255\n",
      "[((2999, 3799), 1.4082225731698261), ((2999, 3397), 3.3587292421282733), ((2999, 3396), 3.45221004873277)]\n",
      "[((2999, 3799), 1.0), ((2999, 3397), 4.0), ((2999, 3396), 4.0)]\n",
      "[17.371523035238063, 17.276989028017876, 16.396599835118717]\n",
      "76745.8069392\n",
      "96842\n",
      "For rank 12 the RMSE is 0.890216118367\n",
      "The best model was trained with rank 8\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "validationForPredictRDD = validationRDD.map(lambda x: (x[0],x[1]))\n",
    "\n",
    "seed = 5L\n",
    "iterations = 5\n",
    "regularizationParameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.03\n",
    "\n",
    "minError = float('inf')\n",
    "bestRank = -1\n",
    "bestIteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(trainingRDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter)\n",
    "    predictedRatingsRDD = model.predictAll(validationForPredictRDD)\n",
    "    error = computeError(predictedRatingsRDD, validationRDD)\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print 'For rank %s the RMSE is %s' % (rank, error)\n",
    "    if error < minError:\n",
    "        minError = error\n",
    "        bestRank = rank\n",
    "\n",
    "print 'The best model was trained with rank %s' % bestRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2d) Testing The Model**\n",
    "#### So far, we used the `trainingRDD` and `validationRDD` datasets to select the best model. To decide how good our model is, we need to use the `testRDD` dataset.  We will use the `bestRank` you determined in part (2c) to create a model for predicting the ratings for the test dataset and then we will compute the RMSE.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((2999, 2720), 1.0), ((2999, 2450), 1.0), ((2999, 2429), 2.0)]\n",
      "[((2999, 2720), 1.4927219427895995), ((2999, 2450), 1.5746678541203836), ((2999, 2429), 2.2985564300693095)]\n",
      "[19.67187198212714, 16.590083688002007, 16.213685704043076]\n",
      "77792.9394322\n",
      "97980\n",
      "The model had a RMSE on the test set of 0.891048561304\n"
     ]
    }
   ],
   "source": [
    " \n",
    "myModel = ALS.train(trainingRDD, 8, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter)\n",
    "testForPredictingRDD = testRDD.map(lambda x: (x[0],x[1]))\n",
    "\n",
    "predictedTestRDD = myModel.predictAll(testForPredictingRDD)\n",
    "   \n",
    "testRMSE = computeError(testRDD, predictedTestRDD)\n",
    "\n",
    "print 'The model had a RMSE on the test set of %s' % testRMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2e) Comparing The Model**\n",
    "#### Looking at the RMSE for the results predicted by the model versus the values in the test set is one way to evalute the quality of our model. Another way to evaluate the model is to evaluate the error from a test set where every rating is the average rating for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average rating for movies in the training set is 3.57409571052\n",
      "[(2999, 2720, 1.0), (2999, 2450, 1.0), (2999, 2429, 2.0)]\n",
      "[(2999, 2720, 3.5740957105180646), (2999, 2450, 3.5740957105180646), (2999, 2429, 3.5740957105180646)]\n",
      "[((2999, 2720), 1.0), ((2999, 2450), 1.0), ((2999, 2429), 2.0)]\n",
      "[((2999, 2720), 3.5740957105180646), ((2999, 2450), 3.5740957105180646), ((2999, 2429), 3.5740957105180646)]\n",
      "[6.6259687269075, 6.6259687269075, 6.6259687269075]\n",
      "123051.930024\n",
      "98032\n",
      "The RMSE on the average set is 1.12036693569\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "trainingAvgRating = trainingRDD.map(lambda x: x[2]).mean()\n",
    "print 'The average rating for movies in the training set is %s' % trainingAvgRating\n",
    "\n",
    "testForAvgRDD = testRDD.map(lambda x: (x[0],x[1], trainingAvgRating))\n",
    "print testRDD.top(3)\n",
    "print testForAvgRDD.top(3)\n",
    "testAvgRMSE = computeError(testRDD, testForAvgRDD)\n",
    "print 'The RMSE on the average set is %s' % testAvgRMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3: Predictions for Yourself**\n",
    "#### You can now predict what movies to recommend to a new user.  In order to do that, we first need to add his ratings to the `ratingsRDD` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most rated movies:\n",
      "(average rating, movie name, number of reviews)\n",
      "(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088)\n",
      "(4.515798462852263, u\"Schindler's List (1993)\", 1171)\n",
      "(4.512893982808023, u'Godfather, The (1972)', 1047)\n",
      "(4.510460251046025, u'Raiders of the Lost Ark (1981)', 1195)\n",
      "(4.505415162454874, u'Usual Suspects, The (1995)', 831)\n",
      "(4.457256461232604, u'Rear Window (1954)', 503)\n",
      "(4.45468509984639, u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 651)\n",
      "(4.43953006219765, u'Star Wars: Episode IV - A New Hope (1977)', 1447)\n",
      "(4.4, u'Sixth Sense, The (1999)', 1110)\n",
      "(4.394285714285714, u'North by Northwest (1959)', 700)\n",
      "(4.379506641366224, u'Citizen Kane (1941)', 527)\n",
      "(4.375, u'Casablanca (1942)', 776)\n",
      "(4.363975155279503, u'Godfather: Part II, The (1974)', 805)\n",
      "(4.358816276202219, u\"One Flew Over the Cuckoo's Nest (1975)\", 811)\n",
      "(4.358173076923077, u'Silence of the Lambs, The (1991)', 1248)\n",
      "(4.335826477187734, u'Saving Private Ryan (1998)', 1337)\n",
      "(4.326241134751773, u'Chinatown (1974)', 564)\n",
      "(4.325383304940375, u'Life Is Beautiful (La Vita \\ufffd bella) (1997)', 587)\n",
      "(4.324110671936759, u'Monty Python and the Holy Grail (1974)', 759)\n",
      "(4.3096, u'Matrix, The (1999)', 1250)\n",
      "(4.309457579972183, u'Star Wars: Episode V - The Empire Strikes Back (1980)', 1438)\n",
      "(4.30379746835443, u'Young Frankenstein (1974)', 553)\n",
      "(4.301346801346801, u'Psycho (1960)', 594)\n",
      "(4.296438883541867, u'Pulp Fiction (1994)', 1039)\n",
      "(4.286535303776683, u'Fargo (1996)', 1218)\n",
      "(4.282367447595561, u'GoodFellas (1990)', 811)\n",
      "(4.27943661971831, u'American Beauty (1999)', 1775)\n",
      "(4.268053855569155, u'Wizard of Oz, The (1939)', 817)\n",
      "(4.267774699907664, u'Princess Bride, The (1987)', 1083)\n",
      "(4.253333333333333, u'Graduate, The (1967)', 600)\n",
      "(4.236263736263736, u'Run Lola Run (Lola rennt) (1998)', 546)\n",
      "(4.233807266982622, u'Amadeus (1984)', 633)\n",
      "(4.232558139534884, u'Toy Story 2 (1999)', 860)\n",
      "(4.232558139534884, u'This Is Spinal Tap (1984)', 516)\n",
      "(4.228494623655914, u'Almost Famous (2000)', 744)\n",
      "(4.2250755287009065, u'Christmas Story, A (1983)', 662)\n",
      "(4.216757741347905, u'Glory (1989)', 549)\n",
      "(4.213358070500927, u'Apocalypse Now (1979)', 539)\n",
      "(4.20992028343667, u'L.A. Confidential (1997)', 1129)\n",
      "(4.204733727810651, u'Blade Runner (1982)', 845)\n",
      "(4.1886120996441285, u'Sling Blade (1996)', 562)\n",
      "(4.184615384615385, u'Braveheart (1995)', 1300)\n",
      "(4.184168012924071, u'Butch Cassidy and the Sundance Kid (1969)', 619)\n",
      "(4.182509505703422, u'Good Will Hunting (1997)', 789)\n",
      "(4.166969147005445, u'Taxi Driver (1976)', 551)\n",
      "(4.162767039674466, u'Terminator, The (1984)', 983)\n",
      "(4.157545605306799, u'Reservoir Dogs (1992)', 603)\n",
      "(4.153333333333333, u'Jaws (1975)', 750)\n",
      "(4.149840595111583, u'Alien (1979)', 941)\n",
      "(4.145015105740181, u'Toy Story (1995)', 993)\n"
     ]
    }
   ],
   "source": [
    "print 'Most rated movies:'\n",
    "print '(average rating, movie name, number of reviews)'\n",
    "for ratingsTuple in movieLimitedAndSortedByRatingRDD.take(50):\n",
    "    print ratingsTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The user ID 0 is unassigned, so we will use it for his ratings. We set the variable `myUserID` to 0 for him. Next, we create a new RDD `myRatingsRDD` with his ratings for at least 10 movie ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My movie ratings: [(0, 260, 5), (0, 3948, 3), (0, 3876, 5), (0, 3885, 2), (0, 3879, 3), (0, 1, 5), (0, 2, 5), (0, 3, 4), (0, 4, 5), (0, 5, 5)]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "myUserID = 0\n",
    "\n",
    "# Note that the movie IDs are the *last* number on each line. A common error was to use the number of ratings as the movie ID.\n",
    "myRatedMovies = [\n",
    "    (myUserID, 260, 5),\n",
    "    (myUserID, 3948, 3),\n",
    "    (myUserID, 3876, 5),\n",
    "    (myUserID, 3885, 2),\n",
    "    (myUserID, 3879, 3),\n",
    "    (myUserID, 1, 5),\n",
    "    (myUserID, 2, 5),\n",
    "    (myUserID, 3, 4),\n",
    "    (myUserID, 4, 5),\n",
    "    (myUserID, 5, 5),\n",
    "     # The format of each line is (myUserID, movie ID, your rating)\n",
    "     # For example, to give the movie \"Star Wars: Episode IV - A New Hope (1977)\" a five rating, you would add the following line:\n",
    "     #   (myUserID, 260, 5),\n",
    "    ]\n",
    "myRatingsRDD = sc.parallelize(myRatedMovies)\n",
    "print 'My movie ratings: %s' % myRatingsRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3b) Add His Movies to Training Dataset**\n",
    "#### We have ratings for a new user, we need to add his ratings to the `training` dataset so that the model will incorporate his preferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset now has 10 more entries than the original training dataset\n"
     ]
    }
   ],
   "source": [
    " \n",
    "trainingWithMyRatingsRDD = trainingRDD.union(myRatingsRDD)\n",
    "\n",
    "print ('The training dataset now has %s more entries than the original training dataset' %\n",
    "       (trainingWithMyRatingsRDD.count() - trainingRDD.count()))\n",
    "assert (trainingWithMyRatingsRDD.count() - trainingRDD.count()) == myRatingsRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3c) Train a Model with New Ratings**\n",
    "#### Now, we train a model with new ratings added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " \n",
    "myRatingsModel = ALS.train(trainingWithMyRatingsRDD, bestRank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3d) Check RMSE for the New Model with New Ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((2999, 2720), 1.0), ((2999, 2450), 1.0), ((2999, 2429), 2.0)]\n",
      "[((2999, 2720), 1.453789410642706), ((2999, 2450), 1.5093341667743103), ((2999, 2429), 2.386441121159943)]\n",
      "[16.107175301086112, 16.01345286023443, 15.941615789776838]\n",
      "77952.6193731\n",
      "97980\n",
      "The model had a RMSE on the test set of 0.891962587976\n"
     ]
    }
   ],
   "source": [
    "predictedTestMyRatingsRDD = myRatingsModel.predictAll(testForPredictingRDD)\n",
    "testRMSEMyRatings = computeError(testRDD, predictedTestMyRatingsRDD)\n",
    "print 'The model had a RMSE on the test set of %s' % testRMSEMyRatings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3e) Predict His Ratings**\n",
    "#### We use the `predictAll` to predict what ratings this user would give to the movies that he did not already provide ratings for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3952, u'Contender, The (2000)'), (3951, u'Two Family House (2000)'), (3950, u'Tigerland (2000)')]\n"
     ]
    }
   ],
   "source": [
    "print moviesRDD.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# Use the Python list myRatedMovies to transform the moviesRDD into an RDD with entries that are pairs of the form (myUserID, Movie ID) and that does not contain any movies that you have rated.\n",
    "myUnratedMoviesRDD = (moviesRDD\n",
    "                      .map(lambda x: (0,x[0])))\n",
    "\n",
    "# Use the input RDD, myUnratedMoviesRDD, with myRatingsModel.predictAll() to predict your ratings for the movies\n",
    "predictedRatingsRDD = myRatingsModel.predictAll(myUnratedMoviesRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3952, 316)]\n",
      "4.28224032239\n",
      "[(3952, 4.282240322386408)]\n",
      "[(3952, (4.282240322386408, 316)), (3951, (4.668850755533288, 35))]\n",
      "[(5.41807559132474, u'Inherit the Wind (1960)'), (5.306571052974393, u\"Schindler's List (1993)\")]\n",
      "My highest rated movies as predicted (for movies with more than 75 reviews):\n",
      "(5.41807559132474, u'Inherit the Wind (1960)')\n",
      "(5.306571052974393, u\"Schindler's List (1993)\")\n",
      "(5.220141784039909, u'Chariots of Fire (1981)')\n",
      "(5.216282204562345, u'Gone with the Wind (1939)')\n",
      "(5.130799798108811, u'My Fair Lady (1964)')\n",
      "(5.128664502096896, u'Mis\\ufffdrables, Les (1995)')\n",
      "(5.123707139367181, u'Green Mile, The (1999)')\n",
      "(5.115580855427306, u'Shakespeare in Love (1998)')\n",
      "(5.110952729867436, u'Gandhi (1982)')\n",
      "(5.106296435804017, u'Miracle on 34th Street (1947)')\n",
      "(5.104918432078982, u'Titanic (1997)')\n",
      "(5.096117700197223, u'Mr. Smith Goes to Washington (1939)')\n",
      "(5.093636792263315, u'October Sky (1999)')\n",
      "(5.082998368860042, u'Philadelphia (1993)')\n",
      "(5.072781109322637, u'Remember the Titans (2000)')\n",
      "(5.071855499653777, u'Sound of Music, The (1965)')\n",
      "(5.062563835537694, u'Shall We Dance? (1937)')\n",
      "(5.05430044890975, u'Sixth Sense, The (1999)')\n",
      "(5.041176213723691, u'Dances with Wolves (1990)')\n",
      "(5.040894986654157, u'Killing Fields, The (1984)')\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Transform movieIDsWithAvgRatingsRDD from part (1b), which has the form (MovieID, (number of ratings, average rating)), into and RDD of the form (MovieID, number of ratings)\n",
    "movieCountsRDD = movieIDsWithAvgRatingsRDD.map(lambda x: (x[0],x[1][0]))\n",
    "print movieCountsRDD.top(1)\n",
    "# Transform predictedRatingsRDD into an RDD with entries that are pairs of the form (Movie ID, Predicted Rating)\n",
    "print predictedRatingsRDD.top(1)[0][2]\n",
    "predictedRDD = predictedRatingsRDD.map(lambda x: (x[1],x[2]))\n",
    "print predictedRDD.top(1)\n",
    "# Use RDD transformations with predictedRDD and movieCountsRDD to yield an RDD with tuples of the form (Movie ID, (Predicted Rating, number of ratings))\n",
    "predictedWithCountsRDD  = (predictedRDD\n",
    "                           .join(movieCountsRDD))\n",
    "print predictedWithCountsRDD.top(2)\n",
    "# Use RDD transformations with PredictedWithCountsRDD and moviesRDD to yield an RDD with tuples of the form (Predicted Rating, Movie Name, number of ratings), for movies with more than 75 ratings\n",
    "ratingsWithNamesRDD = (predictedWithCountsRDD\n",
    "                       .join(moviesRDD)\n",
    "                       .filter(lambda x: x[1][0][1]>75)\n",
    "                       .map(lambda x: (x[1][0][0], x[1][1] )))\n",
    "print ratingsWithNamesRDD.top(2)\n",
    "predictedHighestRatedMovies = ratingsWithNamesRDD.takeOrdered(20, key=lambda x: -x[0])\n",
    "print ('My highest rated movies as predicted (for movies with more than 75 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, predictedHighestRatedMovies)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
